## Проект для «Викишоп» 
Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 

Здесь я обучаю модель классифицировать комментарии на позитивные и негативные. 
Требованием заказчика является значение метрики качества *F1* не меньше 0.75. 

**Описание данных:**

Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак.

## Выводы

В данной работе была проведена классификация комментариев на позитивные и негативные. В исходных данных 159292 строки с комментариями. Максимальная длина строки 5000 символов. 

Предложено 2 варианта решения в BERT и с TfidfVectorizer. 

Поскольку лемматизация и TF-IDF конечно затратны по вычислительной мощности, но не так сильно как получение эмбедингов, то весь массив данных был обработан, лемматизирован и преобразован TfidfVectorizer. Данный способ удовлетваряет требование заказчика в f1 > 0.75. Словом с наибольшим весом в пользу присовения строке класа 1 стало "fuck".

В качестве модели BERT toxic-bert, которая обучена на сэмпле из 6000 строк. На полученных эмбеддингах LGBMClassifier показал прекрасный результат на тестовой выборке в 0.91
